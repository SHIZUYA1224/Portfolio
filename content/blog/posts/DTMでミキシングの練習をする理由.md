---
title: 'DTMでミキシングの練習をする理由'
date: '2026-02-21'
summary: 'このポートフォリオにMarkdownベースのブログ機能を追加しました。'
coverImage: '/HERO.png'
---

# はじめに : DTMでミキシングの練習をする理由

AIの進化により、専門的な知識がなくても楽曲を生成できる時代になりました。
しかし私は、生成そのものよりも **音響設計の工程にこそ価値がある** と考えています。

現時点での私のミキシング技術はまだ発展途上です。それでも継続して取り組んでいるのは、AI時代において求められるのは「音を作る人」ではなく、**意図を設計できる人材** だと考えているからです。

本記事では、どのような将来像を見据えてミキシングを学習しているのかを整理します。

- AI生成音源の再構築・音響最適化
- 配信環境別ラウドネス最適化設計
- 空間メディア向け立体音響再設計
- 感情導線を意識したダイナミクス再構築

---

## AI生成音源の再構築・音響最適化

AIが生成した楽曲は一定水準で整っています。しかし実際に再生してみると、必ずしも「そのまま公開できる状態」とは限りません。

ヘッドホンでは問題なく聞こえても、スピーカーでは低域が膨らみすぎたり、ボーカルが奥に引っ込んでしまうことがあります。

- 小型スピーカーでは低域が不足し、バランスが崩れる
- 車内再生では低域が共振し、不自然な響きになる

AIは音を生成しますが、再生環境までは考慮していません。

そのため私は、生成された音源を「完成品」ではなく「再設計可能な素材」として扱います。

- 不要帯域の整理
- 主役パートの明確化
- ダイナミクスの再設計
- 再生環境を想定したラウドネス調整

音響最適化とは、特定の環境で良く聞こえることではなく、**環境が変わっても破綻しない構造を作ること**だと考えています。

### 今後の課題

帯域整理や音像配置といった基本的な調整は行えるようになりました。しかし、スピーカー環境での検証体制はまだ十分とは言えません。

特に、

- スピーカー再生時の低域の膨らみや共振
- 中域の明瞭度の変化
- 小型デバイス再生時の帯域欠損

といった点については、より実践的な検証を重ねる必要があります。

---

## 配信環境別ラウドネス最適化設計

配信プラットフォームごとにラウドネス基準は異なります。

- Spotify：約 -14 LUFS
- Apple Music：約 -16 LUFS
- YouTube：約 -14 LUFS 前後

仮に -8 LUFS のように過度に音圧を上げた場合、プラットフォーム側で自動的に音量が下げられます。

その結果、

- ダイナミクスが潰れたまま小さく再生される
- 意図した迫力が失われる

といった問題が起きます。

### 今後の課題

現在、ポートフォリオ内の一部楽曲でも課題があります。-14 LUFS に調整しているものの、全体が持ち上がった印象があり、結果として余裕のない音になっている部分があります。

数値が基準内であっても、

- 音像が前に出すぎている
- 奥行きが浅い
- セクション間の抑揚が弱い

と感じる場面があります。

単にLUFSを合わせるだけでは不十分であり、帯域整理とダイナミクス設計を含めた総合的な調整が必要だと認識しています。

---

## 空間メディア向け立体音響再設計

これは私が個人的に目指している領域です。

自作した3D空間内で楽曲を再生し、音を単なるBGMとして扱うのではなく、空間構造の一部として制御したいと考えています。

3D空間では、

- 音の方向
- 距離による減衰
- 空間残響
- 遮蔽物による音の変化

といった要素を設計できます。

例えば、オブジェクトに近づくと音が明瞭になり、離れると残響が強まる。
空間の奥行きに応じて定位が変化する。

そのように、音と空間を連動させた設計を目指しています。

### 今後の課題

現時点では、音そのものへの理解がまだ十分とは言えません。

- 帯域ごとの知覚特性
- 反射音と直接音の関係
- 距離減衰と心理的奥行きの相関

こうした基礎理解をより深める必要があります。

立体音響は演出だけの問題ではなく、音の物理特性と知覚特性の両方を理解する領域です。今後は3D空間構築と並行して、音響理論への理解を高めていきます。
