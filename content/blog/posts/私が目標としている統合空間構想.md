---
title: '私が目標としている統合空間構想'
date: '2026-02-21'
summary: 'このポートフォリオにMarkdownベースのブログ機能を追加しました。'
coverImage: '/HERO.png'
---

### 私が設計している統合空間構想

私が設計している統合空間構想

AIの進化により、映像・音楽・Webサイトといった単体のデジタルコンテンツは、今後ますます低コストで量産されるようになります。

その結果、価値は「制作」そのものから、それらをどう統合し、どう体験として設計するかへ移っていくと私は考えています。

AI時代に強くなるのは、単体のコンテンツを作れる存在ではなく、
複数の要素を統合し、総合演出として設計できる人物や企業です。

私はその方向に自らを成長させるため、
3D空間・AI・音響を統合した「空間そのものがメディアとなる環境」を最終目標として設定しています。

ここで重要なのは、私が直ちにそのサービスを展開するということではありません。

この構想は、現在取り組んでいる

- 3D制作
- AI実装
- 音響設計
- イベント構築

これらを一本の軸で結び、常に目的を見失わないための設計図です。

私は制作物を増やすことよりも、
統合可能な構造を設計できる人間になることを目指しています。

### 空間そのものがメディアとなる環境

私の理想は、リアルタイムで会話可能なAIが存在する空間です。

そこでは単にキャラクターが動くだけではなく、
利用者と対話しながら状況に応じて振る舞いを変える存在として機能します。

同じ空間内では、

- 音楽ライブを開催できる
- 企業が商品を3Dで立体的に紹介できる
- デモンストレーションや教育を行える

といった活動が可能になります。

重要なのは、これらが個別の機能として存在するのではなく、
一つの空間の中で統合されていることです。

会話、音楽、演出、商品体験が分離せず、
空間そのものが体験の媒体になる。

それが私の目指している環境です。

### AI分野の個人的現状

AI分野においては、自作VRMモデルをUnity上で動作させ、
FastAPI・OpenAI API・VoiceVox APIを組み合わせた会話システムの実装まで到達しています。

書籍を参考にしながらではありますが、

- テキスト生成
- API通信
- 音声合成
- Unity側での受信・再生処理

までを一通り構築し、AIと3Dキャラクターを結びつける基礎部分の検証は完了しています。

これは、私が目指す統合空間において、
空間内に存在するAIをどのように動作させるかを理解するための前段実証です。

現段階ではリアルタイム性や遅延管理、大規模同時接続などの課題は残っていますが、
「AIが3D空間内で会話する」構造自体は確認済みです。

あなたの音楽分野は「作曲者」ではなく、音響設計者へ移行中の段階です。
強みと課題の両方が明確に存在しています。

そのまま記事に使える形でまとめます。

⸻

### 音楽分野の個人的現状

音楽分野においては、作曲そのものよりもミキシングと音響設計の理解深化に重点を置いています。

作曲に関しては、

- コード進行設計
- スケールを用いたメロディ構築
- DAW（GarageBand / Logic系）での打ち込み

といった基礎工程は問題なく行えます。

しかし現在は、
ミキシングやマスタリングに対応できるような作曲・編曲
「作れるかどうか」ではなく、どう鳴らすかを設計できるかを考えられる段階に改善しようと考えています。

⸻

取り組んでいる領域

- 帯域整理（不要帯域のカット・役割分担）
- ダイナミクス設計
- ラウドネス基準（-14LUFS前後）の理解
- ヘッドルーム管理
- トランジェント保持
- 音像の明確化

特に、AI生成音源を再構築可能な素材として扱う視点を持ち、
音圧依存ではない構造設計を目指しています。

⸻

現在感じている課題

- ミックスやマスタリングを前提とした作曲・編曲
- マスタリング前のPeakに余裕が少ない
- 帯域管理が甘く、全体が持ち上がって聞こえる
- -14LUFSに合わせてもダイナミクスが不足する
- 音像の奥行きが浅くなる傾向
- スピーカー再生時の低域共振への理解不足

数値上は基準内でも、
質感としての自然さや空間的余裕が足りないという認識があります。

⸻

空間設計との関係
私は音楽を「完成物」としてではなく、
将来的な空間音響設計のための基礎研究と位置付けています。

- 距離減衰
- 空間残響
- 定位設計
- 心理的奥行き

これらを扱うためには、
まず2ch環境での帯域・ダイナミクス理解が不可欠です。

現在はその基礎段階にあります。

### 3D分野の個人的現状

3D分野では、Blenderで制作したコンテンツをポートフォリオ内に実装し、
実際に触れて体験できる構造を構築しています。

現在は主に、

- ROOM（空間モデル）
- MODEL（オブジェクトモデル）

の2系統を導入しています。

単なる静止画像の掲載ではなく、
Web上で実際に回転・移動・視点操作が可能な状態で公開しています。

⸻

ROOMについて
ROOMでは、空間全体を設計対象とし、

- 空間構造
- 視線誘導
- オブジェクト配置
- 余白の使い方

といった要素を意識しています。

ここでは「モデルの完成度」よりも、
空間として成立しているかを重視しています。

⸻

MODELについて
MODELでは、個別オブジェクトを制作し、

- 形状バランス
- パーツ分割
- マテリアル表現
- 軽量化

を意識しています。

特にWeb上で扱うため、
表示負荷と視覚的完成度のバランスを検証しています。

⸻

現在の課題

- モデリング精度の向上（特に有機的形状）
- テクスチャ表現の深化
- 空間演出との連動
- 動的演出との統合設計

現段階では反復による精度向上フェーズにあります。

⸻

統合構想との関係
私にとって3D制作は、作品を作るためのものではなく、
AIと音響が存在するための“器”を設計する工程です。

空間がなければ、

- AIは存在できず
- 音は定位せず
- イベントは成立しません。

そのため現在は、
空間構築力を基礎から積み上げています。
したがって、次の目標がVRChatやCluseterなどのメタバース空間の自作を行う予定です。

### イベント構築の構想

1. 音楽ライブの構想

音楽ライブは音を流す場ではありません。
音・光・空間・視線・行動が同期する制御構造です。

- 照明
- 音響
- 空間演出
- 視線誘導
- 観客とのインタラクション

これらが時間軸上で連動して初めて「体験」になります。

現在は照明制御や舞台設計の知識は発展途上ですが、
一つの発想として、

DAWのMIDIノートを制御信号として扱い、照明や空間演出を同期させる構造

を構想しています。

つまり、

音楽データ ＝ 音声素材
ではなく、

音楽データ ＝ 空間制御トリガー

として扱う設計です。

これは将来的に統合したい重要な機能の一つです。

⸻

2. 企業向け3Dプレゼンテーション

企業プレゼンテーションも、空間化することで構造が変わります。

- 商品の立体分解
- 内部構造の可視化
- 実寸比較
- 動的デモンストレーション

スライドでは「見る」しかできませんが、
空間では「歩く」「近づく」「回り込む」ことが可能になります。

さらに、ARグラスによる実空間重畳型のデモンストレーションも想定しています。

重要なのは、

メタバース＝VRゴーグル必須ではない

ということです。

Webブラウザ、ARデバイス、既存プラットフォーム上でも成立するなら、
それは十分に空間メディアです。

⸻

3. なぜイベント設計が必要か

空間が存在しても、設計がなければ体験は生まれません。

- どの位置で何が起こるのか
- 音はどの方向から鳴るのか
- AIはどの瞬間に介入するのか
- 光はどのタイミングで変化するのか

これらを時間軸と空間軸で構造化することが、イベント設計です。

私は現在、

- 音楽（時間構造）
- 3D（空間構造）
- AI（対話構造）

を個別に鍛えています。

最終的な目標は、
これらを一つの統合演出構造として制御できる設計者になることです。
